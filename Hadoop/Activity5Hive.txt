root@6fe2222571e4:/# vim root/EmpData.csv
root@6fe2222571e4:/# hive
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/local/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-3.3.1/share/hadoop/common/lib/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Hive Session ID = 3aab44c3-f4f6-4a0b-ae24-4b576676741a

Logging initialized using configuration in jar:file:/usr/local/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true
Hive Session ID = 0793b328-128f-4523-90cf-8c3d2b72e11d
Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
hive>
hive> show databases;
OK
default
Time taken: 0.885 seconds, Fetched: 1 row(s)
hive> CREATE DATABASE office;
OK
Time taken: 0.195 seconds
hive> show databases;
OK
default
office
Time taken: 0.022 seconds, Fetched: 2 row(s)
hive> use office;
OK
Time taken: 0.023 seconds
hive> CREATE TABLE employee
    > (id INT, name STRING, dept STRING, yoj INT, salary INT)
    > ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
    > TBLPROPERTIES ("skip.header.line.count"="1");
OK
Time taken: 0.561 seconds
hive> show tables;
OK
employee
Time taken: 0.039 seconds, Fetched: 1 row(s)
hive> DESCRIBE employee;
OK
id                      int
name                    string
dept                    string
yoj                     int
salary                  int
Time taken: 0.21 seconds, Fetched: 5 row(s)
hive> LOAD DATA LOCAL INPATH
    > '/root/EmpData.csv'
    > INTO TABLE employee;
Loading data to table office.employee
OK
Time taken: 0.574 seconds
hive> SELECT * FROM employee;
OK
1       Ian     Quality Assurance       2021    28113
2       Beatrice        Tech Support    2021    35330
3       Vladimir        Human Resources 2020    51445
4       Whitney IT      2020    23818
5       Leslie  Customer Service        2021    59882
6       Bernard IT      2021    50330
7       Mary    Customer Service        2021    26558
8       Jerome  RnD     2021    45333
9       Joshua  IT      2021    59538
10      Keane   Human Resources 2022    46500
11      Velma   Human Resources 2022    19816
12      Rogan   Tech Support    2022    27554
13      Aurelia RnD     2021    20762
14      Merrill Quality Assurance       2021    59660
15      Blaine  Tech Support    2022    28768
Time taken: 1.727 seconds, Fetched: 15 row(s)
hive> SELECT COUNT(*) FROM employee;
Query ID = root_20221123124929_f528bbc6-bf43-4d3e-8f7c-75e204e0b091
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1669203498944_0003, Tracking URL = http://6fe2222571e4:8088/proxy/application_1669203498944_0003/
Kill Command = /usr/local/hadoop/bin/mapred job  -kill job_1669203498944_0003
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2022-11-23 12:49:38,572 Stage-1 map = 0%,  reduce = 0%
2022-11-23 12:49:43,838 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 3.65 sec
2022-11-23 12:49:51,147 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 8.31 sec
MapReduce Total cumulative CPU time: 8 seconds 310 msec
Ended Job = job_1669203498944_0003
MapReduce Jobs Launched:
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 8.31 sec   HDFS Read: 13143 HDFS Write: 102 SUCCESS
Total MapReduce CPU Time Spent: 8 seconds 310 msec
OK
15
Time taken: 22.784 seconds, Fetched: 1 row(s)
hive> ROW FORMAT DELIMITED FIELDS TERMINATED BY ',
    > ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
    > SELECT * fRWRITE DIRECTORY '/user/nandini/output'
    > ROW FORMAT DELIMITED FIELDS TERMINATED BY ',
    > ROW FORMAT DELIMITED FIELDS TERMINATED BY ',exit;
FAILED: ParseException line 3:9 missing EOF at 'fRWRITE' near '*'
hive> INSERT OVERWRITE DIRECTORY '/user/nandini/output'
    > ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
    > SELECT * FROM employee;
Query ID = root_20221123125616_774ae60e-f972-4667-be48-1ccf2e888bca
Total jobs = 3
Launching Job 1 out of 3
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1669203498944_0004, Tracking URL = http://6fe2222571e4:8088/proxy/application_1669203498944_0004/
Kill Command = /usr/local/hadoop/bin/mapred job  -kill job_1669203498944_0004
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0
2022-11-23 12:56:23,851 Stage-1 map = 0%,  reduce = 0%
2022-11-23 12:56:29,078 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.98 sec
MapReduce Total cumulative CPU time: 2 seconds 980 msec
Ended Job = job_1669203498944_0004
Stage-3 is selected by condition resolver.
Stage-2 is filtered out by condition resolver.
Stage-4 is filtered out by condition resolver.
Moving data to directory hdfs://6fe2222571e4:9000/user/nandini/output/.hive-staging_hive_2022-11-23_12-56-16_164_5947052423679237539-1/-ext-10000
Moving data to directory /user/nandini/output
MapReduce Jobs Launched:
Stage-Stage-1: Map: 1   Cumulative CPU: 2.98 sec   HDFS Read: 5646 HDFS Write: 480 SUCCESS
Total MapReduce CPU Time Spent: 2 seconds 980 msec
OK
Time taken: 14.072 seconds
hive> dfs -ls /user/nandini/output;
Found 1 items
-rw-r--r--   1 root supergroup        480 2022-11-23 12:56 /user/nandini/output/000000_0
hive> dfs -cat  /user/nandini/output/000000_0;
1,Ian,Quality Assurance,2021,28113
2,Beatrice,Tech Support,2021,35330
3,Vladimir,Human Resources,2020,51445
4,Whitney,IT,2020,23818
5,Leslie,Customer Service,2021,59882
6,Bernard,IT,2021,50330
7,Mary,Customer Service,2021,26558
8,Jerome,RnD,2021,45333
9,Joshua,IT,2021,59538
10,Keane,Human Resources,2022,46500
11,Velma,Human Resources,2022,19816
12,Rogan,Tech Support,2022,27554
13,Aurelia,RnD,2021,20762
14,Merrill,Quality Assurance,2021,59660
15,Blaine,Tech Support,2022,28768
hive> INSERT OVERWRITE LOCAL DIRECTORY '/root/output'
    >  ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
    > SELECT * FROM employee;
Query ID = root_20221123130214_d0061847-3feb-400f-ad8c-96d07008a80c
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1669203498944_0005, Tracking URL = http://6fe2222571e4:8088/proxy/application_1669203498944_0005/
Kill Command = /usr/local/hadoop/bin/mapred job  -kill job_1669203498944_0005
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0
2022-11-23 13:02:22,312 Stage-1 map = 0%,  reduce = 0%
2022-11-23 13:02:27,512 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.73 sec
MapReduce Total cumulative CPU time: 2 seconds 730 msec
Ended Job = job_1669203498944_0005
Moving data to local directory /root/output
MapReduce Jobs Launched:
Stage-Stage-1: Map: 1   Cumulative CPU: 2.73 sec   HDFS Read: 5662 HDFS Write: 480 SUCCESS
Total MapReduce CPU Time Spent: 2 seconds 730 msec
OK
Time taken: 14.271 seconds
hive> exit;
root@6fe2222571e4:/# ls root/
EmpData.csv  output        sales.csv     textFile.txt
csvFile.csv  pigInput.txt  salesCSV.pig  wordCount.pig
root@6fe2222571e4:/# ls root/output/
000000_0
root@6fe2222571e4:/# cat root/output/000000_0
1,Ian,Quality Assurance,2021,28113
2,Beatrice,Tech Support,2021,35330
3,Vladimir,Human Resources,2020,51445
4,Whitney,IT,2020,23818
5,Leslie,Customer Service,2021,59882
6,Bernard,IT,2021,50330
7,Mary,Customer Service,2021,26558
8,Jerome,RnD,2021,45333
9,Joshua,IT,2021,59538
10,Keane,Human Resources,2022,46500
11,Velma,Human Resources,2022,19816
12,Rogan,Tech Support,2022,27554
13,Aurelia,RnD,2021,20762
14,Merrill,Quality Assurance,2021,59660
15,Blaine,Tech Support,2022,28768
root@6fe2222571e4:/# cat root/output/000000_0 > /root/hresults.csv
root@6fe2222571e4:/# ls root/
EmpData.csv  hresults.csv  pigInput.txt  salesCSV.pig  wordCount.pig
csvFile.csv  output        sales.csv     textFile.txt
root@6fe2222571e4:/# cat root/hresults.csv
1,Ian,Quality Assurance,2021,28113
2,Beatrice,Tech Support,2021,35330
3,Vladimir,Human Resources,2020,51445
4,Whitney,IT,2020,23818
5,Leslie,Customer Service,2021,59882
6,Bernard,IT,2021,50330
7,Mary,Customer Service,2021,26558
8,Jerome,RnD,2021,45333
9,Joshua,IT,2021,59538
10,Keane,Human Resources,2022,46500
11,Velma,Human Resources,2022,19816
12,Rogan,Tech Support,2022,27554
13,Aurelia,RnD,2021,20762
14,Merrill,Quality Assurance,2021,59660
15,Blaine,Tech Support,2022,28768
root@6fe2222571e4:/#